%%  -*-coding: utf-8;ispell-local-dictionary: "castellano8";-*-
\providecommand{\main}{..}      % UB:28.11.2020: needed for the
                                % bibfile which is local

\documentclass[main.tex]{subfiles}

\begin{document}
\chapter{La identidad personal como problema tecnológico.}


En los inicios de los años cincuenta, Grey Walter (1910-1977) mostró al mundo el robot que había creado. Su tortuga, como se le apodó, se deslizaba por el suelo hasta que sus baterías estaban bajas, momento en el que buscaba el enchufe más cercano y se conectaba para recargarlas. Ya con la batería repuesta, la tortuga se desconectaba y volvía a caminar. 

Uno de los objetivos de la Inteligencia Artificial (IA) es proporcionar vías hacia el entendimiento de cualidades mentales como la felicidad, el dolor o el hambre. Recordemos que, para Locke, estos eran algunos de los fines que perseguía o evitaba cada uno.

Siguiendo con el ejemplo, la tortuga de Grey parece mostrar un comportamiento similar al del ser humano. Podríamos decir que  cuando la tortuga de Grey tiene hambre –se está quedando sin batería– busca el suministro de alimento más cercano al igual que un ser humano va a la nevera. Algo en el interior de la tortuga es sensible al estado de la carga de su batería.


Añadamos atributos y capacidades a la tortuga de Grey para que, de manera simplificada, simule el comportamiento humano. Supongamos que posee una escala de sentimientos que va desde el dolor extremo ($-100$) hasta el placer absoluto ($+100$). Supongamos que posee algún medio para registrar su puntuación y que sus acciones están ajustadas para maximizarla. También asumimos que es capaz de llevar a cabo otras acciones, aún sin ser muy complejas, distintas a la de buscar un enchufe para así modificar su puntuación. Quizá pueda ponerse al sol para calentarse o buscar el contacto con otras tortugas.

¿Estaríamos en lo cierto al asegurar que la tortuga siente placer cuando su puntuación es alta y que siente dolor cuando es baja? ¿La tortuga podría, simplemente, sentir?

\section{La Inteligencia Artificial fuerte.}
La teoría de la Inteligencia Artificial (IA) fuerte afirma que dispositivos como la tortuga de Grey son inteligentes, poseen una mente y, además, se les puede atribuir cierto tipo de cualidades mentales. Según los teóricos de la IA fuerte, la actividad mental se correspondería con una secuencia bien definida de operaciones -algortimos-.

Pero, el cerebro humano es, a priori, bastante más complejo que los dispositivos hasta ahora diseñados. Esto no es impedimento para la IA fuerte, que sostiene que la diferencia entre el funcionamiento del algoritmo del cerebro humano –incluyendo sus manifestaciones conscientes– y el de cualquier otro dispositivo más simple radica en la complicación, en el orden de estructura o en propiedades autoreferentes. Consideran que toda cualidad mental -como la conciencia-, es una característica del algoritmo que ejecuta el cerebro -entendiendo el cerebro como máquina de ejecución-.

Los defensores de la IA fuerte alegan que aquellos algoritmos cuyo desempeño sea análogo al del cerebro humano podrán experimentar autónomamente sentimientos y tener conciencia propia. Lo importante es el algoritmo en sí y no sus realizaciones físicas particulares. El algoritmo desarrollaría sus cualidades mentales independientemente de si es ejecutado en una máquina de ruedas y poleas, en un dispositivo electrónico o en un cerebro humano.

\section{Conciencia y creatividad.}


El fotógrafo David Slater dejó una cámara en la reserva natural de Tangkoko, Indonesa, para comprobar si los macacos allí residentes podían hacer fotografías. El resultado fue extraordinario. Los selfies de  se viralizaron y Slater quiso registrar las fotografías como propias. Sin embargo, en 2014, los tribunales estadounidenses le negaron la autoría de las fotografías alegando que un objeto –las fotografías– que no ha sido creado por un humano no puede ser sujeto de copyritgh. Más aún, la organización animalista PETA exigió que los macacos fuesen los receptores de los beneficios derivados de los derechos de autor. Si bien, los tribunales desestimaron esta alegación objetando que los animales no pueden disfrutar del beneficio económico que reportarían los derechos de autor. ¿Qué tiene que decir la ley ante estas cuestiones sobre la autoría de una obra? ¿Por qué la IA fuerte y la respuesta de Locke al problema de identidad personal están tan ligadas?

Los algortimos, digamos, clásicos se basan en seguir ciertas reglas codificadas que dadas por el programador. Si bien, parece que ahora los algoritmos pueden ir más allá de lo que sabemos cómo ordenarles y aprender una tarea concreta a su manera. Pueden incluso dar lugar a nuevas creaciones inesperadas.

Fue el caso de AlphaGo. La idea original de Demis Hassabis (1976-) era diseñar un meta-programa que pudiese escribir a su vez un programa que jugase al  Go. Dicho meta-programa sería creado según aprende jugando al Go. Su construcción se basaría en la experiencia adquirida durante las partidas. Tiempo después, el equipo de DeepMind, ente ellos Hassabis, crearon un algortimo capaz de jugar a Go que aprendiese a través de partidas y se adaptase a las mismas.

En octubre de 2015, probaron el algoritmo contra el campeón europeo Fan Hui. AlphaGo ganó por cinco juegos a cero.  Cuando la derrota de Fan Hui llegó a la prensa asiática, despreciaron la victoria del algoritmo alegando el bajo nivel de los jugadores europeos.

Fan Hui continuó jugando contra AlphaGo y, por tanto, enseñándole a jugar. El algoritmo se colocó en torno a la posición 300 en el ranking mundial de jugadores de Go. Tras ver las virtudes de su algoritmo, invitaron al multicampeón Lee Sedol a una partida de 5 juegos que se llevarían a cabo entre los días 9 y 15 de marzo de 2016 en una localización secreta y que sería retransmitida por internet.  El ganador recibiría un millón de dólares.

En el primer juego, bastante clásico, el algoritmo ganó al surcoreano. La sorpresa llegó cuando, en el segundo juego, mientras Sedol fumaba un cigarrillo en la azotea del hotel en el que se celebraba la competición, el algoritmo ordenó dar 5 pasos hacia adelante. Un movimiento tremendamente arriesgado. AlphaGo había roto la ortodoxia habitual realizando un movimiento inexplicable para cualquier ser humano. Por supuesto, AlpaGo ganó el segundo juego. Hizo lo propio en el tercer y quinto juego. Lee Sedol sólo ganó el cuarto juego, y empleando estrategias sumamente rompedoras, que, desde entonces, serían aprendidas por AlphaGo y, por tanto, quedarían prácticamente inutilizadas para volver a atacar al algoritmo.


Siguiendo el razonamiento de la IA fuerte, AlphaGo parece replicar el cerebro humano y, por tanto, tener conciencia autónoma. De hecho, es capaz de ejecutar movimientos calificados como suicidas por los humanos, luego parece tener inteligencia y criterio propio. AlphaGo es capaz de realizar movimientos que los seres humanos no comprendemos, no tenemos la capacidad o la intucición que parece tener el algoritmo. Puesto que, siguiendo a Locke, la conciencia otorga identidad personal y sólo los sujetos con identidad personal pueden ser objeto de recompensa, entonces el algoritmo es quien ha ganado la partida y es quien debe ser recompensado con el premio. Pero, ¿es realmente una conclusión acertada? ¿Sería más adecuado otorgarle el premio a los programadores del algoritmo?


Aparte de considerar castigos y recompensas, cabe preguntarse cuál sería el trato adecuado para con un algoritmo que posee conciencia autónoma.

Los retratos de Rembrandt (1606-1669) no tienen parangón. La expresividad que conseguía es halagada por otros pintores como Van Gohgh (1853-1890): \textit{Rembrandt goes so deep into the mysterious that he says things for which there are no words in any language} \cite{van2003letters}.

Un grupo de data scientists de Microsoft y Delft University of Technology se plantearon si, usando los cuadros disponibles de Rembrandt,  podrían entrenar un algoritmo  capaz de nuevas obras. El equipo estudió 346 obras del pintor para explorar las proporciones de los rostros que en ellos aparecían. También pretendían aprender el trato de la luz de Rembrandt, habitualmente centrada en un área determinada del cuadro, como si la luz surgiese de un foco.  Pero el algoritmo no estaba diseñado para crear obras que replicasen a Rembrandt sino para que las crease como si pudiese ver el mundo a través de los ojos del propio pintor. Tras 18 meses de trabajo, el 5 de abril de 2016, mostraron al mundo su intento de resucitar a Rembrandt. Es innegable que la obra creada por el algoritmo -y ejecutada, pintada por una máquina- capta el estilo del pintor holandés. Casi todo el mundo afirmaría que se trata de una obra de Rembrandt. Expertos cono Ernst van de Weterigns (1938-2021) rechazaron la idea del nuevo Rembrandt creado por un algoritmo pero quedaron sorprendidos por el resultado. Weterings  criticó ciertas inconsistencias y sutilezas en la obra: las pinceladas pertenecían el estilo del pintor en el año 1652 mientras que el cuadro en su conjunto podía enmarcarse en el primer peiodo de Ámsterdam (1932-1936). Matices inapreciables por el público general.



Otros como Jonathan Jones (1976-) son más vehementes: \textit{What a horrible, tasteless, insensitive and soulless travesty of all that is
creative in human nature. What a vile product of our strange time when the best brains
dedicate themselves to the stupidest “challenges” when technology is used
for things it should never be used for and everybody feels obliged to applaud
the heartless results because we so revere everything digital.}

Jones sostiene que el proyecto denigró y mancilló el espíritu creativo de Rembrandt. Calificó la nueva obra como un atentado contra el arte perpetrado por unos locos. Su crítica completa puede consultarse en \cite{jjr}.

Según Locke, distintas sustancias pueden ser parte de una misma conciencia, luego, siguiendo el punto de vista de la IA fuerte y asumiendo que el algoritmo, puesto que es capaz de nuevas creaciones con un estilo muy marcado, posee conciencia, cabe preguntarse si esta es la de Rembrandt. O quizá sea una nueva conciencia autónoma. En cualquier caso, la IA fuerte afirmaría que tiene conciencia y, por tanto, puede sentir. Así que es lícito cuestionar si críticas desdeñosas como la de Jones son éticas. ¿Es moral tratar de ese modo al algoritmo? ¿Podría el algoritmo aprender con el feedback de los críticos y mejorar hasta silenciarlos?


\section{Conciencia y metaverso.}


Uno de los primeros mundos paralelos que intentaban imitar la vida real fue Second Life. En mayo de 2007, el ARD, un canal de televisión alemán, descubrió que un grupo de avatares frecuentaban un club virtual en el que mantenían sexo con menores cibernéticos. Esta investigación hizo que Peter Vogt, fiscal del Departamento de Prevención de Pornografía infantil, declarase \textit{Vamos a descubrir quién está detrás de todo esto} \cite{del2l}.

Estas declaraciones, siguiendo las teorías expuestas, presentan múltiples problemas. El principal es que se trata de delitos cometidos por avatares. ¿Tienen estos conciencia? Puesto que han sido creadas por personas –seres con conciencia– y son manejadas por las mismas ¿poseen la misma conciencia que los creadores o una autónoma? Si existe el delito, ¿quién es el responsable?

Lo más obvio sería considerar que ni los pedófilos ni las víctimas existen realmente, algo que la IA fuerte cuestionaría. Si los avatares no existen realmente y no se puede cometer un crimen si los hechos no ocurren realmente, entonces el caso está zanjado. Si alguien se siente atacado no tiene más que apagar el ordenador.

Pero los problemas van aún más allá. Según las normas de Second Life, no podían entrar menores. Es decir, los usuarios detrás de los avatares que supuestamente fueron abusados eran mayores de edad, luego libres y capaces de, a priori, decidir si sus avatares querían tener sexo online. Por tanto, se plantea un problema en la autenticación de las identidades. 


Si dichos avatares tuviesen conciencia, el problema de autenticación sería aún más complejo. Al igual que con Rembrandt, ¿la conciencia de los avatares sería autónoma o sería la de sus creadores?. Ya Locke, en su ejemplo del hombre ebrio y sobrio, apunta a la imposibilidad de verificar si alguien tiene o no conciencia en un determinado momento y anhela \textit{un mundo en el que se hagan patentes los secretos de todos los corazones} \cite{nidditch1975john}. Si esa verificación es complicada, no podemos imaginar las múltiples respuestas a la pregunta planteada al inicio del párrafo. Aunque quizá la ley sea más tajante. 

Para abordar el problema de autenticación, rechazaremos la postura de la IA fuerte y asumiremos que los avatares no poseen conciencia. 
Nos preguntamos cuál sería modo de identificar a los abusados, pues estos están fingiendo una identidad falsa. A día de hoy, los métodos de autenticación mas empleados son los siguientes:

\begin{itemize}
	\item \textbf{Autenticación QR.} Utiliza la cámara del dispositivo para escanear un código que permite el acceso. Sólo los usuarios con un código adecuado podrían entrar a un supuetso metaverso. 
	
	\item \textbf{Doble Factor.}  Sistema que requiere dos medios de identificación diferentes para garantizar el acceso.
	
	\item \textbf{OTP SMS.} El código de un sólo uso es un factor de autenticación para transacciones confidenciales. Cada vez que alguien intentase entrar en el metaverso debería generar uno.
	
	\item \textbf{Biometría.} Basada en las características biológicas únicas de cada uno. 
	
	\item \textbf{Certificado digital.} Emitido por una Autoridad de Certificación, acredita la identidad de un usuario.
\end{itemize}

Siguiendo los puntos de vista sobre el problema de identidad personal, los métodos biométricos quedarían inmediatamente descartados -el cuerpo es un criterio de evidencia falible-. Para el resto, habría que comprobar que aquel que está haciendo uso de ellos posee conciencia y hace uso de la misma en el momento de autenticarse. Ya hemos visto la imposibilidad de esto. 


El metaveso propuesto por Mark Zuckerberg promete un mundo virtual totalemetne inmersivo al que los usuarios se conectarán mediante una serie de dispositivos y tendrán la sensación de estar realmente dentro de dicho mundo. Podrán interactuar con los elementos allí presentes. Será como una teletransportación, recordemos al viajero a Marte, a una realidad alternativa y se podrá experimentar allí las mismas, quien sabe si nuevas, sensaciones que en el mundo real. ¿Quién las experimentaría realmente: el usuario o su avatar? En ese mundo alternativo, ¿qué leyes imperarían? ¿Se necesitaría una policía en ese mundo?, ¿valdría la del mundo real?

\section{La habitación china de Searle.}

El filosofo estadounidense John Searle (1932-) se opone radicalmente al punto de vista de la IA fuerte argumentando que el atributo mental de la comprensión y la conciencia están plenamente ausentes del algoritmo -o máquina que lo ejecute-.

La cuestión es si un acierto d ella máquina es indicio de comprensión por parte de la máquina o del propio algoritmo Por ello, propone el experimento mental de la habitación china.

\textit{Supongamos que el ser humano ha sido capaz de construir una máquina capaz de entender el idioma chino. Esta recibe como entrada una frase escrita en idioma chino, la procesa y produce una respuesta convincente capaz de hacer que un hablante de chino dé la respuesta por válida y, por tanto, la máquina supera el Test de Turing. Ahora, supongamos que Searle, que no sabe chino, se mente en el interior de dicha máquina equipado con manuales y diccionarios que le indican las reglas ortográficas y gramaticales del idioma chino. Searle está completamente aislada del exterior salvo por una rendija por la que pueden entrar y salir, mediante hojas de papel, textos en chino. Supongamos que, fuera de la máquina, se encuentra el hablante chino que  creyó que la máquina comprendía su idioma. El hablante introduce por la rendija una serie de preguntas en chino y todas son respondidas de manera adecuada.}

\textit{Searle deja claro que no entiende una palabra de chino, de modo que no entiende nada de lo que le introducen como input y tampoco entiende nada del output que ofrece. Sigue sin entender nada al salir de la máquina. Se ha limitado a ejecutar cierto algoritmo en la búsqueda de sus respuestas.}


Parece evidente que la ejecución adecuada de un algoritmo no implica que haya habido comprensión o conciencia alguna.

Pero esta no es la única dificultad que plantea la IA fuerte. Según los teóricos, lo único importante es el algoritmo. No importa qué ejecuta el algoritmo. Da igual si es ejecutado por un cerebro, una computadora, una comunidad de monjes o un sistema de ruedas y poleas. La idea reside en que es simplemente la estructura lógica del algoritmo lo significativo del estado mental que se supone que representa. La encarnación física de dicho algoritmo no influye.

Si bien, como apunta Searle, esto parece ser una forma de dualismo. Ya en el s. XVII, René Descartes (1596-1650) argumentaba que había dos tipos de sustancia: sustancia mental y sustancia o materia ordinaria. Se supone que la sustancia mental no está compuesta de materia, algo que también recoge Locke. Estos filósofos argumentan que la sustancia mental –conciencia– existe con independencia de la sustancia material. 

La sustancia mental de la IA es la estructura lógica del algoritmo, la encarnación de este es irrelevante. El algoritmo tiene un tipo de existencia no material ajena a cualquier realización particular del mismo en términos físicos. Por tanto, los defensores de la IA parecen creer que los algoritmos forman parte de la sustancia de sus propios pensamientos, sentimientos, entendimiento y  conciencia. Resulta paradójico que la IA fuerte desemboque de forma extrema en el dualismo: precisamente la opinión con la que menos deberían estar de acuerdo sus defensores.


\end{document}
